import os
import random
import sys
import time
import yaml

from netam.framework import crepe_exists
sys.path.append("..")
from shmex.shm_zoo import train_model, trained_model_str, trained_model_path, fixed_model_path
from shmex.shm_eval import write_test_accuracy

configfile: "config_human.yml"

species = config["species"]
model_names = config["model_names"]
train_data_nicknames = config["train_data_nicknames"]
test_data_nicknames = config["test_data_nicknames"]
training_methods = config["training_methods"]
seeds = range(config["replicate_count"])
restrict_evaluation_to_shmoof_region = True
min_log_prob = config["min_log_prob"]

fixed_model_names = ["s5f","cnn_ind_med-shmoof_small"]
final_output_path = f"_ignore/{species}_model_compare.csv"
final_fig_path = f"_ignore/{species}_model_compare.pdf"


def trained_model_yml(model_name, data_nickname, training_method, seed):
    return f"{trained_model_path(model_name, data_nickname, training_method, seed)}.yml"


def fixed_model_yml(model_name):
    return f"{fixed_model_path(model_name)}.yml"


def test_output_path(model_name, data_nickname, training_method, seed, dataset_name):
    trained_model = trained_model_str(model_name, data_nickname, training_method, seed)
    return f"_ignore/test_output/{trained_model}-ON-{dataset_name}.csv"


def test_fig_path(model_name, data_nickname, training_method, seed, dataset_name):
    trained_model = trained_model_str(model_name, data_nickname, training_method, seed)
    return f"_ignore/test_output/{trained_model}-ON-{dataset_name}.pdf"


def test_output_path_fixed(model_name, dataset_name):
    return f"_ignore/test_output_fixed/{model_name}-ON-{dataset_name}.csv"


rule all:
    input: final_output_path, final_fig_path


rule train_model:
    output:
        trained_model=trained_model_yml("{model_name}", "{data_nickname}", "{training_method}", "{seed}")
    run:
        train_model(wildcards.model_name, wildcards.data_nickname, wildcards.training_method, int(wildcards.seed))


rule write_test_accuracy:
    input:
        trained_model=trained_model_yml("{model_name}", "{data_nickname}", "{training_method}", "{seed}"),
    output:
        test_output=test_output_path("{model_name}", "{data_nickname}", "{training_method}", "{seed}", "{dataset_name}"),
        test_fig=test_fig_path("{model_name}", "{data_nickname}", "{training_method}", "{seed}", "{dataset_name}")
    run:
        crepe_prefix = os.path.splitext(input.trained_model)[0]
        write_test_accuracy(crepe_prefix, wildcards.dataset_name, min_log_prob, "_ignore/test_output", restrict_evaluation_to_shmoof_region)


rule write_test_accuracy_fixed:
    output:
        test_output=test_output_path_fixed("{model_name}", "{dataset_name}")
    run:
        write_test_accuracy(fixed_model_path(wildcards.model_name), wildcards.dataset_name, "_ignore/test_output_fixed", restrict_evaluation_to_shmoof_region)


rule concatenate_csvs:
    input:
        csvs = [
            test_output_path(m, d, tm, s, td)
                for m in model_names
                for d in train_data_nicknames
                for tm in training_methods
                for s in seeds
                for td in test_data_nicknames
            ] + [
            test_output_path_fixed(m, d)
                for m in fixed_model_names
                for d in test_data_nicknames
            ]
    output:
        combined_csv = final_output_path
    shell:
        """
        epam concatenate_csvs $(echo '{input.csvs}' | tr ' ' ',') {output.combined_csv}
        """


rule concatenate_figs:
    input:
        figs = [
            test_fig_path(m, d, tm, s, td)
                for m in model_names
                for d in train_data_nicknames
                for tm in training_methods
                for s in [0]
                #for s in seeds
                for td in test_data_nicknames
            ]
    output:
        combined_fig = final_fig_path
    shell:
        """
        pdfunite {input.figs} {output.combined_fig}
        """
