{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matsen/mambaforge/envs/epam/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from netam import framework, models\n",
    "from netam.framework import calculate_loss\n",
    "from epam.torch_common import pick_device\n",
    "\n",
    "from epam.torch_common import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shmoof_data_path = \"/Users/matsen/data/shmoof_edges_11-Jan-2023_NoNode0_iqtree_K80+R_masked.csv\"\n",
    "train_df, val_df = framework.load_shmoof_dataframes(shmoof_data_path, val_nickname=\"59\") #, sample_count=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal Performance Shaders\n",
      "we have 44330 training examples and 4686 validation examples\n"
     ]
    }
   ],
   "source": [
    "kmer_length = 3\n",
    "max_length = 410\n",
    "\n",
    "train_dataset = framework.SHMoofDataset(train_df, kmer_length=kmer_length, max_length=max_length)\n",
    "val_dataset = framework.SHMoofDataset(val_df, kmer_length=kmer_length, max_length=max_length)\n",
    "\n",
    "device = pick_device()\n",
    "train_dataset.to(device)\n",
    "val_dataset.to(device)\n",
    "\n",
    "print(f\"we have {len(train_dataset)} training examples and {len(val_dataset)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNPPModel(\n",
       "  (kmer_embedding): Embedding(65, 10)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (conv): Conv1d(10, 9, kernel_size=(11,), stride=(1,), padding=same)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear): Linear(in_features=9, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNPPModel(nn.Module):\n",
    "    def __init__(self, dataset, embedding_dim, num_filters, kernel_size, dropout_rate):\n",
    "        super(CNNPPModel, self).__init__()\n",
    "        self.kmer_count = len(dataset.kmer_to_index)\n",
    "        self.kmer_embedding = nn.Embedding(self.kmer_count, embedding_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout=dropout_rate) \n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(in_features=num_filters, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, encoded_parents, masks):\n",
    "        kmer_embeds = self.kmer_embedding(encoded_parents)\n",
    "        kmer_embeds = self.pos_encoder(kmer_embeds)\n",
    "        kmer_embeds = kmer_embeds.permute(0, 2, 1)  # Transpose for Conv1D\n",
    "        conv_out = F.relu(self.conv(kmer_embeds))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        conv_out = conv_out.permute(0, 2, 1)  # Transpose back for Linear layer\n",
    "        log_rates = self.linear(conv_out).squeeze(-1)\n",
    "        rates = torch.exp(log_rates * masks)\n",
    "        return rates\n",
    "\n",
    "\n",
    "model = CNNPPModel(train_dataset, embedding_dim=10, num_filters=9, kernel_size=11, dropout_rate=0.1)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 47/100 [07:59<09:00, 10.20s/it, loss_diff=8.853e-08, lr=3.2e-5]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067934</td>\n",
       "      <td>0.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.061113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.060955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064786</td>\n",
       "      <td>0.060025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063781</td>\n",
       "      <td>0.059193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062944</td>\n",
       "      <td>0.058698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062498</td>\n",
       "      <td>0.058554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062246</td>\n",
       "      <td>0.058803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.058573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.058348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.061682</td>\n",
       "      <td>0.058314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.061612</td>\n",
       "      <td>0.058389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.061616</td>\n",
       "      <td>0.058275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.061530</td>\n",
       "      <td>0.058169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.061495</td>\n",
       "      <td>0.058308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.061560</td>\n",
       "      <td>0.058215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.061505</td>\n",
       "      <td>0.058125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.061484</td>\n",
       "      <td>0.058197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.061433</td>\n",
       "      <td>0.058096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.058049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.061439</td>\n",
       "      <td>0.058087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.061427</td>\n",
       "      <td>0.058086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.061407</td>\n",
       "      <td>0.058057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.061421</td>\n",
       "      <td>0.058146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.061427</td>\n",
       "      <td>0.058119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.061299</td>\n",
       "      <td>0.057944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.061218</td>\n",
       "      <td>0.057959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.057957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.061215</td>\n",
       "      <td>0.057972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.061239</td>\n",
       "      <td>0.057943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.061229</td>\n",
       "      <td>0.057976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.061197</td>\n",
       "      <td>0.057941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.061163</td>\n",
       "      <td>0.057930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.061173</td>\n",
       "      <td>0.057939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.061155</td>\n",
       "      <td>0.057935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.061163</td>\n",
       "      <td>0.057927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.061163</td>\n",
       "      <td>0.057938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.061161</td>\n",
       "      <td>0.057931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.061147</td>\n",
       "      <td>0.057931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.061165</td>\n",
       "      <td>0.057931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.057932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.061143</td>\n",
       "      <td>0.057929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.057928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.061147</td>\n",
       "      <td>0.057928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.061161</td>\n",
       "      <td>0.057927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.057927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.057926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.061153</td>\n",
       "      <td>0.057926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  val_loss\n",
       "0     0.067934  0.063368\n",
       "1     0.066426  0.061113\n",
       "2     0.065325  0.060955\n",
       "3     0.064786  0.060025\n",
       "4     0.063781  0.059193\n",
       "5     0.062944  0.058698\n",
       "6     0.062498  0.058554\n",
       "7     0.062246  0.058803\n",
       "8     0.062053  0.058573\n",
       "9     0.061686  0.058348\n",
       "10    0.061682  0.058314\n",
       "11    0.061612  0.058389\n",
       "12    0.061616  0.058275\n",
       "13    0.061530  0.058169\n",
       "14    0.061495  0.058308\n",
       "15    0.061560  0.058215\n",
       "16    0.061505  0.058125\n",
       "17    0.061484  0.058197\n",
       "18    0.061433  0.058096\n",
       "19    0.061441  0.058049\n",
       "20    0.061439  0.058087\n",
       "21    0.061427  0.058086\n",
       "22    0.061407  0.058057\n",
       "23    0.061421  0.058146\n",
       "24    0.061427  0.058119\n",
       "25    0.061299  0.057944\n",
       "26    0.061218  0.057959\n",
       "27    0.061226  0.057957\n",
       "28    0.061215  0.057972\n",
       "29    0.061239  0.057943\n",
       "30    0.061229  0.057976\n",
       "31    0.061197  0.057941\n",
       "32    0.061163  0.057930\n",
       "33    0.061173  0.057939\n",
       "34    0.061155  0.057935\n",
       "35    0.061163  0.057927\n",
       "36    0.061163  0.057938\n",
       "37    0.061161  0.057931\n",
       "38    0.061147  0.057931\n",
       "39    0.061165  0.057931\n",
       "40    0.061144  0.057932\n",
       "41    0.061143  0.057929\n",
       "42    0.061145  0.057928\n",
       "43    0.061147  0.057928\n",
       "44    0.061161  0.057927\n",
       "45    0.061146  0.057927\n",
       "46    0.061154  0.057926\n",
       "47    0.061153  0.057926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burrito = framework.Burrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, min_learning_rate=1e-4, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = burrito.train(epochs=100)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here's a simple CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 36/100 [05:57<10:35,  9.94s/it, loss_diff=8.273e-08, lr=3.2e-5]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066718</td>\n",
       "      <td>0.062412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063459</td>\n",
       "      <td>0.058582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061533</td>\n",
       "      <td>0.058262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.058330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061124</td>\n",
       "      <td>0.058286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.058141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.061040</td>\n",
       "      <td>0.058301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.058131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.061024</td>\n",
       "      <td>0.058290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061003</td>\n",
       "      <td>0.058262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.061004</td>\n",
       "      <td>0.058199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.060970</td>\n",
       "      <td>0.058184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.061010</td>\n",
       "      <td>0.058220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.060816</td>\n",
       "      <td>0.058054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.060724</td>\n",
       "      <td>0.058063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.060741</td>\n",
       "      <td>0.058070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.060744</td>\n",
       "      <td>0.057990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.058042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.060730</td>\n",
       "      <td>0.058067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.060746</td>\n",
       "      <td>0.058026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.058046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.058046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.057991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.060653</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.060652</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.060641</td>\n",
       "      <td>0.058018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.060614</td>\n",
       "      <td>0.058009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.060608</td>\n",
       "      <td>0.058007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.060612</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.058007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.060609</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.058006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.060607</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.060611</td>\n",
       "      <td>0.058006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.060599</td>\n",
       "      <td>0.058005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  val_loss\n",
       "0     0.066718  0.062412\n",
       "1     0.063459  0.058582\n",
       "2     0.061533  0.058262\n",
       "3     0.061214  0.058330\n",
       "4     0.061124  0.058286\n",
       "5     0.061086  0.058141\n",
       "6     0.061040  0.058301\n",
       "7     0.061056  0.058131\n",
       "8     0.061024  0.058290\n",
       "9     0.061003  0.058262\n",
       "10    0.061004  0.058199\n",
       "11    0.060970  0.058184\n",
       "12    0.061010  0.058220\n",
       "13    0.060816  0.058054\n",
       "14    0.060724  0.058063\n",
       "15    0.060741  0.058070\n",
       "16    0.060744  0.057990\n",
       "17    0.060727  0.058042\n",
       "18    0.060730  0.058067\n",
       "19    0.060746  0.058026\n",
       "20    0.060737  0.058046\n",
       "21    0.060738  0.058046\n",
       "22    0.060666  0.057991\n",
       "23    0.060645  0.058000\n",
       "24    0.060653  0.058000\n",
       "25    0.060652  0.058005\n",
       "26    0.060641  0.058018\n",
       "27    0.060614  0.058009\n",
       "28    0.060608  0.058007\n",
       "29    0.060612  0.058005\n",
       "30    0.060605  0.058007\n",
       "31    0.060609  0.058005\n",
       "32    0.060605  0.058006\n",
       "33    0.060607  0.058005\n",
       "34    0.060611  0.058006\n",
       "35    0.060601  0.058005\n",
       "36    0.060599  0.058005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.CNNModel(train_dataset, embedding_dim=10, num_filters=9, kernel_size=11, dropout_rate=0.1)\n",
    "model.to(device)\n",
    "\n",
    "burrito = framework.Burrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, min_learning_rate=1e-4, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = burrito.train(epochs=100)\n",
    "losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
