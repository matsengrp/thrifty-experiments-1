{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PersiteWrapper\n",
    "\n",
    "This is where I develop the `PersiteWrapper` and test if we should use regularization. \n",
    "The answer is no. \n",
    "It is in `models.py` now, without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from netam import framework, models\n",
    "from netam.common import pick_device, print_parameter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = framework.load_shmoof_dataframes(\"/Users/matsen/data/shmoof_edges_11-Jan-2023_NoNode0_iqtree_K80+R_masked.csv\", val_nickname=\"59\") #, sample_count=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal Performance Shaders\n",
      "we have 44330 training examples and 4686 validation examples\n"
     ]
    }
   ],
   "source": [
    "kmer_length = 1\n",
    "site_count = 410\n",
    "\n",
    "train_dataset = framework.SHMoofDataset(train_df, kmer_length=kmer_length, site_count=site_count)\n",
    "val_dataset = framework.SHMoofDataset(val_df, kmer_length=kmer_length, site_count=site_count)\n",
    "\n",
    "device = pick_device()\n",
    "train_dataset.to(device)\n",
    "val_dataset.to(device)\n",
    "\n",
    "print(f\"we have {len(train_dataset)} training examples and {len(val_dataset)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersiteWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    This wraps another model, but adds a per-site component.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, dataset, penalty_weight=0.0):\n",
    "        super(PersiteWrapper, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.site_count = dataset.max_length\n",
    "        self.penalty_weight = penalty_weight\n",
    "        self.log_site_rates = nn.Embedding(self.site_count, 1)\n",
    "\n",
    "    def forward(self, encoded_parents, masks):\n",
    "        base_model_rates = self.base_model(encoded_parents, masks)\n",
    "        sequence_length = encoded_parents.size(1)\n",
    "        positions = torch.arange(sequence_length, device=encoded_parents.device)\n",
    "        log_site_rates = self.log_site_rates(positions).T\n",
    "        rates = base_model_rates * torch.exp(log_site_rates)\n",
    "        return rates\n",
    "    \n",
    "    def regularization_loss(self):\n",
    "        reg_loss = torch.sum(self.log_site_rates.weight ** 2)\n",
    "        reg_loss *= self.penalty_weight\n",
    "        return reg_loss \n",
    "\n",
    "    @property\n",
    "    def site_rates(self):\n",
    "        # Convert site log rates to linear space\n",
    "        return torch.exp(self.log_site_rates.weight).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SHMoofDataset' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m base_model_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_sml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_med\u001b[39m\u001b[38;5;124m\"\u001b[39m: models\u001b[38;5;241m.\u001b[39mCNNModel(train_dataset, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, filter_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_lrg\u001b[39m\u001b[38;5;124m\"\u001b[39m: models\u001b[38;5;241m.\u001b[39mCNNModel(train_dataset, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, filter_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m      5\u001b[0m     }\n\u001b[1;32m      7\u001b[0m base_model \u001b[38;5;241m=\u001b[39m base_model_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_med\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m base_model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/re/netam/netam/models.py:143\u001b[0m, in \u001b[0;36mCNNModel.__init__\u001b[0;34m(self, kmer_length, embedding_dim, filter_count, kernel_size, dropout_prob)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m, kmer_length, embedding_dim, filter_count, kernel_size, dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    142\u001b[0m ):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkmer_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmer_embedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmer_count, embedding_dim)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(\n\u001b[1;32m    146\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39membedding_dim,\n\u001b[1;32m    147\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39mfilter_count,\n\u001b[1;32m    148\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[1;32m    149\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m~/re/netam/netam/models.py:51\u001b[0m, in \u001b[0;36mKmerModel.__init__\u001b[0;34m(self, kmer_length)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmer_length \u001b[38;5;241m=\u001b[39m kmer_length\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_kmers \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_kmers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkmer_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmer_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_kmers)\n",
      "File \u001b[0;32m~/re/netam/netam/common.py:21\u001b[0m, in \u001b[0;36mgenerate_kmers\u001b[0;34m(kmer_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_kmers\u001b[39m(kmer_length):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Our strategy for kmers is to have a single representation for any kmer that isn't in ACGT.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# This is the first one, which is simply \"N\", and so this placeholder value is 0.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     all_kmers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkmer_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     ]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_kmers) \u001b[38;5;241m<\u001b[39m torch\u001b[38;5;241m.\u001b[39miinfo(torch\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_kmers\n",
      "\u001b[0;31mTypeError\u001b[0m: 'SHMoofDataset' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "base_model_dict = {\n",
    "        \"cnn_sml\": models.CNNModel(train_dataset, embedding_dim=6, filter_count=14, kernel_size=7, dropout_prob=0.0),\n",
    "        \"cnn_med\": models.CNNModel(train_dataset, embedding_dim=9, filter_count=9, kernel_size=11, dropout_prob=0.1),\n",
    "        \"cnn_lrg\": models.CNNModel(train_dataset, embedding_dim=7, filter_count=19, kernel_size=11, dropout_prob=0.3),\n",
    "    }\n",
    "\n",
    "base_model = base_model_dict[\"cnn_med\"]\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 53/100 [12:20<10:57, 13.98s/it, loss_diff=-1.747e-07, lr=6.4e-6] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.058413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.061871</td>\n",
       "      <td>0.058413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.061884</td>\n",
       "      <td>0.058413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.061885</td>\n",
       "      <td>0.058414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.061869</td>\n",
       "      <td>0.058413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  val_loss\n",
       "49    0.061875  0.058413\n",
       "50    0.061871  0.058413\n",
       "51    0.061884  0.058413\n",
       "52    0.061885  0.058414\n",
       "53    0.061869  0.058413"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_burrito = framework.SHMBurrito(train_dataset, val_dataset, base_model, batch_size=1024, learning_rate=0.1, min_learning_rate=1e-5, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = base_burrito.train(epochs=100)\n",
    "losses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Turn off training mode for the base model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      3\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model.eval() # Turn off training mode for the base model\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = PersiteWrapper(base_model_dict[\"cnn_med\"], train_dataset)\n",
    "model.to(device)\n",
    "burrito = framework.SHMBurrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, min_learning_rate=1e-5, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = burrito.train(epochs=100)\n",
    "losses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Move to 0-indexing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m shmoof_positions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m cnn_residuals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlog_site_rates\u001b[38;5;241m.\u001b[39mweight)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m cnn_residuals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(cnn_residuals)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMutability\u001b[39m\u001b[38;5;124m'\u001b[39m: cnn_residuals})\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Merge dataframes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Load position mutabilities\n",
    "shmoof_positions = pd.read_csv('_ignore/original_shmoof/mutabilities_position.tsv', sep='\\t')\n",
    "# Move to 0-indexing\n",
    "shmoof_positions[\"Position\"] -= 1\n",
    "cnn_residuals = torch.exp(model.log_site_rates.weight).cpu().squeeze().detach().numpy()\n",
    "cnn_residuals = pd.DataFrame({'Position': np.arange(len(cnn_residuals)), 'Mutability': cnn_residuals})\n",
    "\n",
    "# Merge dataframes\n",
    "merged_positions = pd.merge(shmoof_positions, cnn_residuals, on='Position', suffixes=('_shmoof', '_cnn_residuals'))\n",
    "merged_positions.sort_values(by='Position', inplace=True)\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(merged_positions['Position'], merged_positions['Mutability_shmoof'], label='Shmoof')\n",
    "plt.plot(merged_positions['Position'], merged_positions['Mutability_cnn_residuals'], label='CNN Residuals')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Mutability')\n",
    "plt.ylim(0, 4)\n",
    "\n",
    "plt.title('Comparison of Position Mutabilities: Shmoof vs. CNN Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'num_filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m PersiteWrapper(base_model, train_dataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_filters'"
     ]
    }
   ],
   "source": [
    "base_model = models.CNNModel(train_dataset, embedding_dim=9, num_filters=9, kernel_size=11, dropout_prob=0.1)\n",
    "model = PersiteWrapper(base_model, train_dataset)\n",
    "model.to(device)\n",
    "burrito = framework.SHMBurrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, min_learning_rate=1e-5, l2_regularization_coeff=1e-6)\n",
    "print(\"starting training...\")\n",
    "losses = burrito.train(epochs=100)\n",
    "losses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with regularization coefficient 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'num_filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coeff \u001b[38;5;129;01min\u001b[39;00m regularization_coeffs:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with regularization coefficient \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoeff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m PersiteWrapper(base_model, train_dataset, penalty_weight\u001b[38;5;241m=\u001b[39mcoeff)\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_filters'"
     ]
    }
   ],
   "source": [
    "regularization_coeffs = [0, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "results = []\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for coeff in regularization_coeffs:\n",
    "    print(f\"Training with regularization coefficient {coeff}\")\n",
    "    base_model = models.CNNModel(train_dataset, embedding_dim=9, num_filters=9, kernel_size=11, dropout_prob=0.1)\n",
    "    model = PersiteWrapper(base_model, train_dataset, penalty_weight=coeff)\n",
    "    model.to(device)\n",
    "    burrito = framework.SHMBurrito(train_dataset, val_dataset, model, batch_size=1024, learning_rate=0.1, l2_regularization_coeff=1e-7)\n",
    "    loss_history = burrito.train(epochs=100)\n",
    "    final_training_loss = loss_history['train_loss'].iloc[-1]\n",
    "    final_validation_loss = loss_history['val_loss'].iloc[-1]\n",
    "    if final_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = final_validation_loss\n",
    "        best_model = model\n",
    "\n",
    "    results.append({\n",
    "        'Regularization': coeff,\n",
    "        'Final_Training_Loss': final_training_loss,\n",
    "        'Final_Validation_Loss': final_validation_loss\n",
    "    })\n",
    "\n",
    "regularization_results_df = pd.DataFrame(results)\n",
    "regularization_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regularization_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mregularization_results_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegularization\u001b[39m\u001b[38;5;124m'\u001b[39m], regularization_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal_Training_Loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(regularization_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegularization\u001b[39m\u001b[38;5;124m'\u001b[39m], regularization_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal_Validation_Loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regularization_results_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(regularization_results_df['Regularization'], regularization_results_df['Final_Training_Loss'], label='Training Loss', marker='o')\n",
    "plt.plot(regularization_results_df['Regularization'], regularization_results_df['Final_Validation_Loss'], label='Validation Loss', marker='x')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Regularization Coefficient')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Effect of L2 Regularization on Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "regularization_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: don't regularize the site rates, it doesn't help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
